{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56720c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import array\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0c7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcm_to_wav(pcm_file):\n",
    "    # 입력 PCM 파일 경로\n",
    "    pcm_file_path = 'data/problem3/task3_04.pcm'\n",
    "\n",
    "    # 출력 WAV 파일 경로\n",
    "    wav_file_path = 'output.wav'\n",
    "\n",
    "    # 오디오 파라미터 설정\n",
    "    sample_width = 2  # 2바이트 샘플 너비 (16비트)\n",
    "    frame_rate = 16000  # 프레임 속도 (샘플링 레이트)\n",
    "    num_channels = 1  # 모노 오디오\n",
    "\n",
    "    # PCM 파일을 읽기\n",
    "    with open(pcm_file_path, 'rb') as pcm_file:\n",
    "        pcm_data = pcm_file.read()\n",
    "\n",
    "    # PCM 데이터를 WAV 파일로 쓰기\n",
    "    with wave.open(wav_file_path, 'wb') as wav_file:\n",
    "        wav_file.setnchannels(num_channels)\n",
    "        wav_file.setsampwidth(sample_width)\n",
    "        wav_file.setframerate(frame_rate)\n",
    "        wav_file.writeframes(pcm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92212a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models\\\\2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models\\2stems\\model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "from spleeter.separator import Separator\n",
    "from os import path\n",
    "\n",
    "# Spleeterの設定（2stemsモデルを使ってボーカルと伴奏に分離）\n",
    "separator = Separator('spleeter:2stems')\n",
    "\n",
    "\n",
    "# PCMファイルを読み込む\n",
    "# ここでは、'input_audio.pcm'が16 bit, 16 kHz, MonoのPCMファイルと仮定\n",
    "# input_audio_path = 'input_audio.pcm'\n",
    "#input_audio_path = path.join(path.dirname(__file__), \"task3_04.pcm\")\n",
    "input_audio_path = 'output.wav'\n",
    "\n",
    "# 分離処理を行う\n",
    "# 分離されたオーディオは'output_directory'内に保存される\n",
    "output_directory = 'output_audio'\n",
    "separator.separate_to_file(input_audio_path, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d072695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "pcm_files = glob.glob('../../data/문제3/*.pcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0daea1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcm_to_wav(pcm_file):\n",
    "    # 입력 PCM 파일 경로\n",
    "    for idx, pcm_file_path in enumerate(pcm_files):\n",
    "        # 출력 WAV 파일 경로\n",
    "        wav_file_path = 'output' + str(idx+1) + '.wav'\n",
    "\n",
    "        # 오디오 파라미터 설정\n",
    "        sample_width = 2  # 2바이트 샘플 너비 (16비트)\n",
    "        frame_rate = 16000  # 프레임 속도 (샘플링 레이트)\n",
    "        num_channels = 1  # 모노 오디오\n",
    "\n",
    "        # PCM 파일을 읽기\n",
    "        with open(pcm_file_path, 'rb') as pcm_file:\n",
    "            pcm_data = pcm_file.read()\n",
    "\n",
    "        # PCM 데이터를 WAV 파일로 쓰기\n",
    "        with wave.open(wav_file_path, 'wb') as wav_file:\n",
    "            wav_file.setnchannels(num_channels)\n",
    "            wav_file.setsampwidth(sample_width)\n",
    "            wav_file.setframerate(frame_rate)\n",
    "            wav_file.writeframes(pcm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd260178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8143639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json(audio_file):\n",
    "    intervals_jsons = []\n",
    "\n",
    "    min_silence_length = 70\n",
    "    intervals = detect_nonsilent(audio_file,\n",
    "                               min_silence_len=min_silence_length,\n",
    "                               silence_thresh=-32.64)\n",
    "  \n",
    "    if intervals[0][0] != 0:\n",
    "        intervals_jsons.append({'start':0,'end':intervals[0][0]/1000,'tag':'침묵'}) \n",
    "    \n",
    "    non_silence_start = intervals[0][0]\n",
    "    before_silence_start = intervals[0][1]\n",
    "\n",
    "    for interval in intervals:\n",
    "        interval_audio = audio_file[interval[0]:interval[1]]\n",
    "\n",
    "    if (interval[0] - before_silence_start) >= 2000:\n",
    "        intervals_jsons.append({'start':non_silence_start/1000,'end':(before_silence_start+200)/1000,'tag':'비침묵'}) \n",
    "        non_silence_start = interval[0]-200\n",
    "        intervals_jsons.append({'start':before_silence_start/1000,'end':interval[0]/1000,'tag':'침묵'}) \n",
    "    before_silence_start = interval[1]\n",
    "\n",
    "    if non_silence_start != len(audio_file):\n",
    "        intervals_jsons.append({'start':non_silence_start/1000,'end':len(audio_file)/1000,'tag':'비침묵'})\n",
    "\n",
    "    return intervals_jsons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
